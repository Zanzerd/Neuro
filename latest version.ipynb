{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from keras.layers.convolutional import Conv2D\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save(img, path = \"C:\\\\Users\\\\Pankratz\\\\Desktop\\\\Jupyter_lab2\\\\\"): \n",
    "    \n",
    "    assert img == 'check.jpg' or img == 'cross.jpg', \"значение img должно быть 'check.jpg' или 'cross.jpg' \"\n",
    "    \n",
    "    img_path = os.path.join(path, img)\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # читаем изображение сразу чёрно-белым\n",
    "    if img == 'cross.jpg': \n",
    "        image = image[20:727, 60:727] # обрезаем ненужные места со скана \n",
    "        max_x = 17\n",
    "        max_y = 18\n",
    "        new_path = 'C:\\\\Users\\\\Pankratz\\\\Desktop\\\\Jupyter_lab2\\\\images\\\\training data\\\\0' # сразу кодируем X как 0\n",
    "    elif img == 'check.jpg': \n",
    "        image = image[25:735, 32:736] # обрезаем ненужные места со скана\n",
    "        max_x = 18 # в листах с крестиками и галочками разное число символов в каждой строке\n",
    "        max_y = 17\n",
    "        new_path = 'C:\\\\Users\\\\Pankratz\\\\Desktop\\\\Jupyter_lab2\\\\images\\\\training data\\\\1' # сразу кодируем V как 1\n",
    "    \n",
    "    size = 32 \n",
    "    final_wide = max_x*size # рассчитываем во сколько раз уменьшим картинку\n",
    "    r = float(final_wide) / image.shape[1]\n",
    "    dim = (final_wide, int(image.shape[0] * r))\n",
    "\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    # gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(resized, (5, 5), 1) \n",
    "    result = cv2.threshold(blurred, 235, 255, cv2.THRESH_BINARY)[1] #преобразованное изображение\n",
    "    \n",
    "    i = 0\n",
    "    x0 = 0\n",
    "    y0 = 0\n",
    "    count_x = 0\n",
    "    \n",
    "    while count_x < max_x: # цикл по строкам\n",
    "        count_y = 0\n",
    "        x0 = 0\n",
    "        while count_y < max_y: # цикл по столбцам\n",
    "            cropped = result[x0:x0+size, y0:y0+size]\n",
    "            final_path = os.path.join(new_path, \"{0}.jpg\".format(i))\n",
    "            cv2.imwrite(final_path, cropped)\n",
    "            x0 += size\n",
    "            i += 1\n",
    "            count_y +=1\n",
    "        y0 += size\n",
    "        count_x += 1\n",
    "    \n",
    "    return i \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_array, train_answers, my_path = 'C:\\\\Users\\\\Pankratz\\\\Desktop\\\\Jupyter_lab2\\\\images'):\n",
    "    classes = ['0', '1']\n",
    "    directory1 = os.path.join(my_path, 'training data')\n",
    "    for c in classes:\n",
    "        directory_classes = os.path.join(directory1, c)\n",
    "        for pic in tqdm(os.listdir(directory_classes)):\n",
    "            stock = cv2.imread(os.path.join(directory_classes, pic), cv2.IMREAD_GRAYSCALE) \n",
    "            train_array.append(stock / 255)\n",
    "            train_answers.append(c)\n",
    "    \n",
    "    \n",
    "    #images = [cv2.imread(file) for file in glob.glob(\"path/to/files/*.png\")]\n",
    "    \n",
    "    #shfl = list(zip(train_array, train_answers))\n",
    "    #random.shuffle(shfl)\n",
    "    #train_array, train_answers = zip(*shfl)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models \n",
    "\n",
    "classes = ['0', '1']\n",
    "\n",
    "def one_layer_dense():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = 'relu', name = 'input'))\n",
    "    model.add(Dense(len(classes), activation = 'softmax', name = 'output'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "def many_layers_dense():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = 'relu', name = 'input'))\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dense(len(classes), activation = 'softmax', name = 'output'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "def conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 8, kernel_size = (3,3), activation = 'relu', input_shape = (32, 32, 1)))\n",
    "    model.add(MaxPooling2D((3,3), strides = 1))\n",
    "    model.add(Conv2D(filters = 6, kernel_size = (3,3), activation = 'relu', input_shape = (32, 32, 1)))\n",
    "    model.add(MaxPooling2D((3,3), strides = 1))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(len(classes), activation = 'softmax', name = 'output'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['categorical_accuracy'])\n",
    "    return model\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answers(model, X_pred, num_pred, conv = False): \n",
    "    \n",
    "    if conv == True:\n",
    "        X_pred = X_pred.reshape(X_pred.shape[0], 32, 32, 1 ) \n",
    "        \n",
    "    arr_pred = np.array(random.choices(X_pred, k = num_pred)) #случайно перемешиваем поданный массив\n",
    "    predictions = model.predict(arr_pred) #генерируем предсказания\n",
    "\n",
    "    for p in range(len(predictions)):\n",
    "        if predictions[p][0] > 0.95: #0.95 - порог уверенности в том что картинка принадлежит к типу\n",
    "            print('cross \\n')\n",
    "        elif predictions[p][1] > 0.95:\n",
    "            print('check \\n')\n",
    "        else:\n",
    "            print('i dunno \\n')\n",
    "        cv2.imshow('w', arr_pred[p]) #\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one layer model\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "a = crop_and_save(\"check.jpg\") \n",
    "b = crop_and_save(\"cross.jpg\") \n",
    "sum = a+b\n",
    "\n",
    "load_data(X_train, y_train)\n",
    "\n",
    "X_train = (np.array(X_train))\n",
    "y_train = np.array(y_train)\n",
    "y_train_encoded = (keras.utils.to_categorical(y_train))\n",
    "#print(X_train.shape, y_train_encoded.shape)\n",
    "#print(y_train_encoded)\n",
    "\n",
    "\n",
    "X_pred1 = X_train[:2] #выделяем немного данных для демонстрации model.predict\n",
    "y_pred1 = y_train_encoded[:2] #с разных концов упорядоченного датасета, чтобы попадались картинки обоих типов\n",
    "X_pred2 = X_train[-2:]\n",
    "y_pred2 = y_train_encoded[-2:] \n",
    "\n",
    "X_test = X_train[2:100] #выделяем примерно шестую часть данных для тестового сета \n",
    "y_test = y_train_encoded[2:100]\n",
    "\n",
    "X_train = X_train[100:-2]\n",
    "y_train_encoded = y_train_encoded[100:-2]\n",
    "\n",
    "model1 = one_layer_dense()\n",
    "model1.fit(X_train, y_train_encoded, validation_split = 0.2, batch_size = 17, epochs = 18)\n",
    "\n",
    "results = model1.evaluate(X_test, y_test, batch_size = 20)\n",
    "print('\\n test loss, test acc: {0}'.format(results))\n",
    "\n",
    "X_pred = np.concatenate((X_pred1, X_pred2))\n",
    "num_pred = 4 #количество делаемых предсказаний\n",
    "# y_test = np.concatenate((y_test1, y_test2))\n",
    "# ответы не нужны для предсказаний\n",
    "print('Предсказания модели: \\n')\n",
    "predict_answers(model1, X_pred, 4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#many layers model\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "a = crop_and_save(\"check.jpg\") \n",
    "b = crop_and_save(\"cross.jpg\") \n",
    "sum = a+b\n",
    "\n",
    "load_data(X_train, y_train)\n",
    "\n",
    "X_train = (np.array(X_train))\n",
    "y_train = np.array(y_train)\n",
    "y_train_encoded = (keras.utils.to_categorical(y_train))\n",
    "#print(X_train.shape, y_train_encoded.shape)\n",
    "#print(y_train_encoded)\n",
    "\n",
    "\n",
    "X_pred1 = X_train[:2] #выделяем немного данных для демонстрации model.predict\n",
    "y_pred1 = y_train_encoded[:2] #с разных концов упорядоченного датасета, чтобы попадались картинки обоих типов\n",
    "X_pred2 = X_train[-2:]\n",
    "y_pred2 = y_train_encoded[-2:] \n",
    "\n",
    "X_test = X_train[2:100] #выделяем примерно шестую часть данных для тестового сета \n",
    "y_test = y_train_encoded[2:100]\n",
    "\n",
    "X_train = X_train[100:-2]\n",
    "y_train_encoded = y_train_encoded[100:-2]\n",
    "\n",
    "model2 = many_layers_dense()\n",
    "model2.fit(X_train, y_train_encoded, validation_split = 0.2, batch_size = 17, epochs = 18)\n",
    "\n",
    "results = model2.evaluate(X_test, y_test, batch_size = 20)\n",
    "print('\\n test loss, test acc: {0}'.format(results))\n",
    "\n",
    "X_pred = np.concatenate((X_pred1, X_pred2))\n",
    "num_pred = 4 #количество делаемых предсказаний\n",
    "# y_test = np.concatenate((y_test1, y_test2))\n",
    "# ответы не нужны для предсказаний\n",
    "print('Предсказания модели: \\n')\n",
    "predict_answers(model2, X_pred, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional model\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "a = crop_and_save(\"check.jpg\") \n",
    "b = crop_and_save(\"cross.jpg\") \n",
    "sum = a+b\n",
    "\n",
    "load_data(X_train, y_train)\n",
    "\n",
    "X_train = (np.array(X_train))\n",
    "y_train = np.array(y_train)\n",
    "y_train_encoded = (keras.utils.to_categorical(y_train))\n",
    "#print(X_train.shape, y_train_encoded.shape)\n",
    "#print(y_train_encoded)\n",
    "\n",
    "\n",
    "X_pred1 = X_train[:2] #выделяем немного данных для демонстрации model.predict\n",
    "y_pred1 = y_train_encoded[:2] #с разных концов упорядоченного датасета, чтобы попадались картинки обоих типов\n",
    "X_pred2 = X_train[-2:]\n",
    "y_pred2 = y_train_encoded[-2:] \n",
    "\n",
    "X_test = X_train[2:100] #выделяем примерно шестую часть данных для тестового сета \n",
    "y_test = y_train_encoded[2:100]\n",
    "\n",
    "X_train = X_train[100:-2]\n",
    "y_train_encoded = y_train_encoded[100:-2]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 1)\n",
    "\n",
    "model3 = conv_model()\n",
    "model3.fit(X_train, y_train_encoded, validation_split = 0.2, batch_size = 17, epochs = 18)\n",
    "\n",
    "results = model3.evaluate(X_test, y_test, batch_size = 20)\n",
    "print('\\n test loss, test acc: {0}'.format(results))\n",
    "\n",
    "X_pred = np.concatenate((X_pred1, X_pred2))\n",
    "num_pred = 4 #количество делаемых предсказаний\n",
    "print('Предсказания модели: \\n')\n",
    "predict_answers(model3, X_pred, 4, conv = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
