{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, InputLayer, LSTM, SimpleRNN, GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определяем архитектуру используемых нейросетей и заранее задаём размеры батчей\n",
    "\n",
    "Для двухслойной LSTM был выбран больший размер батчей, т.к. обучение сети занимает большое время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_batches = 32\n",
    "gru_batches = 32\n",
    "lstm1_batches = 32\n",
    "lstm2_batches = 128\n",
    "\n",
    "def rnn(X, y, shape):\n",
    "  model = Sequential()\n",
    "  model.add(InputLayer(input_shape = shape))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(SimpleRNN(256))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "  return model\n",
    "\n",
    "def gru(X, y, shape):\n",
    "  model = Sequential()\n",
    "  model.add(InputLayer(input_shape = shape))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(GRU(256, return_sequences = False, unroll = True))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "  return model  \n",
    "\n",
    "def lstm1(X,y, shape):\n",
    "  model = Sequential()\n",
    "  model.add(InputLayer(input_shape = shape))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2])))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(y.shape[1], activation='softmax'))\n",
    "  model.compile(loss ='categorical_crossentropy', optimizer ='adam')\n",
    "  return model\n",
    "\n",
    "def lstm2(X,y, shape):\n",
    "  model = Sequential()\n",
    "  model.add(InputLayer(input_shape = shape))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(LSTM(256, return_sequences = True, input_shape = (X.shape[1], X.shape[2]))) #batch_input_shape = (lstm2_batches, X.shape[1], X.shape[2])\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(LSTM(256, return_sequences = False, stateful = False))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем и обрабатываем датасет (текст)\n",
    "При препроцессинге текст был приведён к общему регистру и из него были убраны: большинство знаков пунктуации, буквы латиницы (в исходном тексте изредка встречались короткие фразы на французском) и лишние пробелы.\n",
    "\n",
    "Создаётся два словаря для сопоставления каждого встречающегося в тексте символа некоторому целому числу и наоборот. \n",
    "Входные данные кодируются по принципу one-hot encoding - единицы ставятся напротив встречающегося в данной позиции символа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Символьная длина отформатированного текста: 211342\n",
      "Всего встречается различных символов: 38\n",
      "Эти символы: [' ', '!', ',', '.', '?', 'e', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я']\n",
      "Число фрагментов: 211292\n",
      "(211292, 50, 38)\n",
      "(211292, 38)\n"
     ]
    }
   ],
   "source": [
    "filename = \"Dost_notepad.txt\"\n",
    "text1 = open(filename, 'r', encoding='utf-8').read()\n",
    "text1 = text1.lower()\n",
    "text1 = re.sub('[#()*:;018\\-\\'\\\"\\nacdghimnopqrstuvxl]', '', text1)\n",
    "text1 = re.sub('\\s{2,}', ' ', text1)\n",
    "chars = sorted(list(set(text1)))\n",
    "char_to_int1 = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_chars1 = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(text1)\n",
    "n_vocab1 = len(chars)\n",
    "print(\"Символьная длина отформатированного текста:\", n_chars)\n",
    "print(\"Всего встречается различных символов:\", n_vocab1)\n",
    "print(\"Эти символы:\", chars)\n",
    "\n",
    "\n",
    "fragments = []\n",
    "next_chars = []\n",
    "step = 1\n",
    "length = 50\n",
    "\n",
    "for k in range(0, len(text1) - length, step):\n",
    "    fragments.append(text1[k : k + length])\n",
    "    next_chars.append(text1[k + length])\n",
    "print(\"Число фрагментов:\", len(fragments))\n",
    "\n",
    "X2 = np.zeros((len(fragments), length, n_vocab1), dtype=np.bool)\n",
    "y2 = np.zeros((len(fragments), n_vocab1), dtype=np.bool) \n",
    "for m, fragment in enumerate(fragments):\n",
    "    for t, char in enumerate(fragment):\n",
    "        X2[m, t, char_to_int1[char]] = 1\n",
    "    y2[m, char_to_int1[next_chars[m]]] = 1\n",
    "print(X2.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные функции\n",
    "\n",
    "Функция sample используется при генерации текста вместо обычного np.argmax(), она обеспечивает некоторую случайность при генерации символов с помощью мультиномиального распределения и позволяет варьировать степень этой \"разнообразности\" с помощью temperature.\n",
    "\n",
    "Функция generate отвечает непосредственно за генерацию текста, начиная с случайно выбранного отрывка исходного текста, и была вынесена сюда просто для удобства. За это удобство и нежелание повторять один и тот же код, однако, пришлось заплатить большим числом аргументов функции (чтобы не было конфликта между глобальными переменными двух разных датасетов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate(model, text, length, n_vocab, char_to_int, int_to_chars, temperature = 1.0):\n",
    "  start = np.random.randint(0, len(text)- length - 1)\n",
    "  sentence = text[start : start + length]\n",
    "  print(\"Генерируем начиная с отрывка:\")\n",
    "  print(\"\\\"\" + sentence + \"\\\"\") \n",
    "  print(\"Генерация: \")    \n",
    "  for i in range(500):\n",
    "    x_pred = np.zeros((1, length, n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "      x_pred[0, t, char_to_int[char]] = 1.0\n",
    "    prediction = model.predict(x_pred, verbose=0)\n",
    "    #index = np.argmax(prediction)\n",
    "    index = sample(prediction[0], temperature = temperature)\n",
    "    result = int_to_chars[index]\n",
    "    sys.stdout.write(result)\n",
    "    sentence += result\n",
    "    sentence = sentence[1:len(sentence)]\n",
    "  print (\"\\n Генерация окончена.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаём и обучаем однослойную RNN сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_1layer = rnn(X2, y2, shape = (length, n_vocab1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "\n",
    "filepath=\"RNN-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "rnn_1layer.fit(X2, y2, epochs=epochs, batch_size=rnn_batches, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"RNN-weights-improvement-14-2.4017.hdf5\"\n",
    "rnn_1layer.load_weights(filename)\n",
    "#opt = RMSprop(learning_rate=0.01)\n",
    "rnn_1layer.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "rnn_1layer.fit(X2, y2, epochs=epochs, batch_size=rnn_batches, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация однослойной RNN сети:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерируем начиная с отрывка:\n",
      "\"баранам и проч., и проч. вот муравьи совершенно др\"\n",
      "Генерация: \n",
      "уго может быть по признаки на так на себя на и потому что на и выдь ставали  о воторин придомне положали не порому на и посторал я в потом на стали по подомал я на посте на по посторит любил за от не подомал я на поста и собельно и вы примей потом не посто не посто не старал я вы приз и на и потому что примо на и вы да от разимень не за от котором приво во все это продом ени на сто на она было по подем не посто не от разво призамил я но посел то на моне поставил я и на постовикал я продил на на \n",
      " Генерация окончена.\n"
     ]
    }
   ],
   "source": [
    "filename = \"RNN-weights-improvement-14-2.4017.hdf5\"\n",
    "rnn_1layer.load_weights(filename)\n",
    "rnn_1layer.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "generate(rnn_1layer, text1, length, n_vocab1, char_to_int1, int_to_chars1, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаём и обучаем однослойную LSTM сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1layer = lstm1(X2, y2, shape = (length, n_vocab1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "filepath=\"LSTM1-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "lstm_1layer.fit(X2, y2, epochs=epochs, batch_size=lstm1_batches, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "211292/211292 [==============================] - 214s 1ms/step - loss: 1.7283\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.72834, saving model to LSTM1-weights-improvement-01-1.7283.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x237962e1d88>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "filename = \"LSTM1-weights-improvement-99-1.7102.hdf5\"\n",
    "\n",
    "filepath=\"LSTM1-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "lstm_1layer.fit(X2, y2, epochs=epochs, batch_size=lstm1_batches, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация однослойной LSTM сети:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерируем начиная с отрывка:\n",
      "\"ы. мало того с волнением и страстью будет говорить\"\n",
      "Генерация: \n",
      " к подвали. неровнок ведь тот, значит, я воображал к селе ощущать, что у нас вам смеятия, потому что я тебе не мог тоже бывало что. да и не переплавилась, была вельне идетлы. своий вас, и потому вы только делать со плавить клавить себя, и в том, что я ее только много завязнув борогу за столо до попелокних каи видитиль уже не полюбил и сам с резортиченким к нечамими запротилась вас неньми, все будет потому что она уверите сордут, до тогда в содволе, потому что он не стал было положить ощещение на\n",
      " Генерация окончена.\n"
     ]
    }
   ],
   "source": [
    "filename = \"LSTM1-weights-improvement-99-1.7102.hdf5\"\n",
    "lstm_1layer.load_weights(filename)\n",
    "lstm_1layer.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "generate(lstm_1layer, text1, length, n_vocab1, char_to_int1, int_to_chars1, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаём и обучаем однослойную GRU сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_1layer = gru(X2, y2, shape = (length, n_vocab1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "filepath=\"GRU-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "gru_1layer.fit(X2, y2, epochs=epochs, batch_size=gru_batches, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация однослойной GRU сети:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерируем начиная с отрывка:\n",
      "\"ельно случалось страдать, но вы нисколько не уважа\"\n",
      "Генерация: \n",
      "ть, ала а вырвыл и на что она уме не свои желание может дойрет тебя на них соонаничей и меня, варительно потемится. ведь у не столы о вывела. а теловито отрочал, что он скавет только себе в дела оменно, не только припомнили меня за вам а рассказывался не смыхнуте совезунных хоторого, кокойно у достоил зачем выпертены и еще он был передо мной не за вс уви отвязаться. я в первой прилечны потому что о меня в комом. не было в векомиза. и и всего этого приервал сейка дурга те, когда ее у с безворгала\n",
      " Генерация окончена.\n"
     ]
    }
   ],
   "source": [
    "filename = \"GRU-weights-improvement-30-1.8857.hdf5\"\n",
    "gru_1layer.load_weights(filename)\n",
    "gru_1layer.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "generate(gru_1layer, text1, length, n_vocab1, char_to_int1, int_to_chars1, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Новый датасет: загрузка и обработка \n",
    "\n",
    "Три однослойных нейронных сети обучались на одном и том же тексте, для разнообразия используем для обучения двухслойной LSTM сети другой текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Символьная длина отформатированного текста: 1284941\n",
      "Всего встречается различных символов: 38\n",
      "Эти символы: [' ', '!', ',', '.', '?', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё']\n",
      "Число фрагментов: 1284891\n",
      "(1284891, 50, 38)\n",
      "(1284891, 38)\n"
     ]
    }
   ],
   "source": [
    "filename = \"Idiot_notepad2.txt\"\n",
    "text2 = open(filename, 'r', encoding='utf-8').read()\n",
    "text2 = text2.lower()\n",
    "text2 = re.sub('[#()*:;0124678\\-\\'\\\"\\nacdeghi\\]\\[\\xa0mbfjlyznopqrstuvx]', '', text2)\n",
    "text2 = re.sub('\\s{2,}', ' ', text2)\n",
    "\n",
    "chars = sorted(list(set(text2)))\n",
    "char_to_int2 = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_chars2 = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(text2)\n",
    "n_vocab2 = len(chars)\n",
    "print(\"Символьная длина отформатированного текста:\", n_chars)\n",
    "print(\"Всего встречается различных символов:\", n_vocab2)\n",
    "print(\"Эти символы:\", chars)\n",
    "\n",
    "length = 50\n",
    "fragments = []\n",
    "next_chars = []\n",
    "step = 1\n",
    "\n",
    "for k in range(0, len(text2) - length, step):\n",
    "    fragments.append(text2[k : k + length])\n",
    "    next_chars.append(text2[k + length])\n",
    "print(\"Число фрагментов:\", len(fragments))\n",
    "\n",
    "X2 = np.zeros((len(fragments), length, n_vocab2), dtype=np.bool)\n",
    "y2 = np.zeros((len(fragments), n_vocab2), dtype=np.bool)\n",
    "for m, fragment in enumerate(fragments):\n",
    "    for t, char in enumerate(fragment):\n",
    "        X2[m, t, char_to_int2[char]] = 1\n",
    "    y2[m, char_to_int2[next_chars[m]]] = 1\n",
    "print(X2.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаём и обучаем двухслойную LSTM сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_2layers = lstm2(X2, y2, shape = ((length, n_vocab2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "\n",
    "filepath=\"LSTM2-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "lstm_2layers.fit(X2, y2, epochs=epochs, batch_size=lstm2_batches, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"LSTM2-weights-improvement-04-1.4042.hdf5\"\n",
    "lstm_2layers.load_weights(filename)\n",
    "epochs = 20\n",
    "lstm_2layers.fit(X2, y2, epochs=epochs, batch_size=lstm2_batches, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация двухслойной LSTM сети:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерируем начиная с отрывка:\n",
      "\", пробормотал ганя, а кстати, скажите мне, как вы \"\n",
      "Генерация: \n",
      "я длма ш боже поссмер, то! объясняя клевку? впрочем, а именно... ксшелав аделаида? до рогожин жьл вварх, да и мечьов спотоинлягивал с, не одуже исет, хверял, хнибаг, много сезочек и мата и от просьой объявления ногой у радуката. она понятья участницу, нисколько бут свои низвы только отлюдите струю бохапили, и допросил однако же, в мешку! однако же, говорила, я это если уж любил истогич, мавичкой князь. с дя я с сила сплучше на тогодичусь, эту жизнь кнцзы? неншко аделаиды илы пряснешься, дин гося\n",
      " Генерация окончена.\n"
     ]
    }
   ],
   "source": [
    "filename = \"LSTM2-weights-improvement-19-1.7737.hdf5\"\n",
    "#optimizer = RMSprop(learning_rate=0.01)\n",
    "lstm_2layers.load_weights(filename)\n",
    "lstm_2layers.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "generate(lstm_2layers, text2, length, n_vocab2, char_to_int2, int_to_chars2, temperature = 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
